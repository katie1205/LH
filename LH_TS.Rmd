
---
title: "LuteinizingHormone"
author: "Katie"
date: "February 1, 2019"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
library(astsa)
library(TSA)
```

#Background
The luteinizing hormone (LH) necessitates fertility in humans. Female ovulation is induced by a rapid surge of LH, which can be measured by analyzing blood samples. Understanding changes in LH levels during ovulation could be useful in assessing a woman's fertility and potentially guiding conception. 

#Problem 
A female patient has provided a series of blood samples from which the LH levels have been measured.The goal of this activity was to analyze changes in LH hormone levels during ovulation through answering the following questions:

 * Is the LH hormone level over time a stationary process?
 * Does a suitable model exist that could be used to predict future hormone levels?
 * If a model exists, what is the equation for the model?

#Data Source
The data were obtained from library(datasets) in R, but was was originally released in a Biostatistical reference book (Diggens, 1990). The data set contains 48 samples at 10-minute intervals that were obtained from the female patient.

#Exploring Data & Assessing Stationarity
The data were visualized in a time series plot, as shown below. The autocorrelations were also plotted in order to assess stationarity. The plots were examined to determine if the behavior was consistent with that of any known classes of time series models, such as the autoregressive or moving average models. 

```{r lh, echo = FALSE}

plot(lh, type = "o", main = "LH Levels Over Time",ylab="LH Levels",xlab="Time in Seconds")
acf(lh, lag.max = 40, main = "LH Sample ACF")  #significant ACF at lag 1, ACF approximately zero                                                            elsewhere => AR(1)
```

The autocorrelations at various lags were plotted as shown above. The autocorrelation appeared to decay after the first lag, and remained within the confidence bounds thereafter. The apparent lack of dependence of the ACF on time is consistent with stationarity. Furthermore, the series did not appear to exhibit any strong or persistant trends, aside from a few peaks and valleys, that would violate stationarity conditions.

In terms of candidate models, an autocorrelation that decays after the first lag could suggest a first order moving average. However, it is also possible that the series could be autoregressive, if the slight oscillations contained within the confidence bounds of the correlogram are not regarded as insignificant. It is possible that, instead, these autocorrelations are simply *close*, but not necessarily equal, to zero. If that is the case, then the ACF could be interpreted as "tailing off" rather than  "dying out", which would be more consistent with the expected behavior for an autoregressive series. 

To test these theories, the partial acf should also be generated, plotted, and examined. The pacf behavior should then be compared to the general expectations of both AR and MA models.

```{r,echo=FALSE}
pacf(lh, main="LH Sample PACF",lag.max=40)
```

As illustrated in the above plot, the partial autocorrelations appear to "die out" after lag=1 and remain within the confidence bounds thereafter. This behavior is more consistent with that of an AR(1). However, as was the case with the acf, it is conceivable that the series could be a moving average if we regard the lags within the confidence bounds as non-zero.

#Analyzing & Selecting Models
In addition to full and partial autocorrelations, information criteria was also used to select the optimal model. Aikake Information Criterion (AIC) and Bayesian Information Criterion (BIC) both assign scores to models based on both goodness-of-fit and model complexity, with the key difference being that BIC penalizes complexity more than AIC. The auto.arima() function applies AIC and BIC over all possible models and selects the model with the best (lowest) score.The function also considers the corrected Aikake Information Criterion ($AIC_c$), which also akes the sample size into account. This is important because larger samples more accurately reflect the population than smaller samples. The result of the function is shown below. 

```{r,echo=FALSE,message=FALSE}
library(TSA)
library(astsa)
library(forecast)
(m1 <-auto.arima(lh))  #suggestS AR(1)
```

As shown above, auto.arima() recommended an AR(1) model of the form $x_t=0.5739x_{t-1}+2.4133$. This seemed 
reasonable, since an AR(1) was one of the initial candidates based on the ACF and PACF.

#Evaluating Model Assumptions
The model residuals were plotted and analyzed to determine if any model assumptions were violated. According to these assumptions, the residuals should be stationary and independent with mean zero.

The sarima() function was used to test the model assumptions. The function outputs a time series plot, a correlogram, and a Normal Q-Q plot for the standardized residuals to evaluate residual stationarity and check for any patterns. The output also includes a plot for the p-values of the Ljung Box test, which assesses residual indepedence. 

```{r echo = FALSE}
#M1
mean(m1$residuals)
X<-sarima(lh,1,0,0)
```

The residual mean was 0.0002 and the residual correlograms resembled that of a white noise series, with (approximately) zero ACF for lag > 0. Dependence of residuals can be assessed via the Ljung Box Test under the null hypothesis that the residuals are independent. The p-values for all Q-statistics exceeded $\alpha=0.05$. This indicated that that the null hypothesis need not be rejected and that the residual independence assumption had not been violated. 

#Comparison to Theory & Other Samples
To further evaluate the model, the theoretical/population ACF for the model was compared to that of the lh hormone. For further confirmation, several random samples of the model were simulated and the ACFs were compared to those of = the lh sample and the population. The purpose of the simulated samples was to gain insight into how samples of the model deviate from the population. Multiple samples were simulated before setting the seed that produced the series plotted below. 

```{r echo = FALSE}
#LH Sample correlogram
acf(lh, lag.max = 40, main = "LH Sample ACF")

#Theoretical correlogram for M1
h = 1:40
plot(h, (0.5739)^h, type = "h", ylim = c(-0.2,0.6), main = "Theoretical ACF")
points(h, (0.5739)^h)
abline(h = 0)

#Simulated Sample correlogram for M1
set.seed(634324)
ar1_sim<-arima.sim(model=list(ar=0.5739),n=40)
acf(ar1_sim,lag.max=40,main="Simulated Sample ACF")
```


#Conclusion
Based on the patterns observed in the sample ACF, the mangitue of $\hat{\phi}$, the goodness of the fit, and the analysis of the residuals, the LH sample likely a stationary AR(1) process. The equation for the model could be $x_t=0.5739x_{t-1}+2.4133$.

In terms of stationarity, the sample ACF converged to zero, in accordance with that of a stationary series. The coefficient, $\hat{\phi}$=0.5739, also confirmed stationarity, since -1<${\phi}$<1.


#References

P.J. Diggle (1990) Time Series: A Biostatistical Introduction. Oxford, table A.1, series 3


